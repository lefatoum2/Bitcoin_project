{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1560a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "M:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "M:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import config\n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tweepy as tw\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "from pydantic import BaseModel\n",
    "from classify import remove_noise\n",
    "from nltk.tokenize import word_tokenize\n",
    "import utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf4a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = utils.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a814b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet(BaseModel):\n",
    "    tweet: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34472f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_tweet(tweet: Tweet):\n",
    "    custom_tokens = remove_noise(word_tokenize(tweet))\n",
    "    result = classifier.classify(dict([token, True] for token in custom_tokens))\n",
    "    return {\"sentiment\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3178d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(config.consumer_key, config.consumer_secret)\n",
    "auth.set_access_token(config.access_token, config.access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2868dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 16:34:36.550 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run M:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "st.title(\"Twitter Live Sentiment Visualizer (beta)\")\n",
    "\n",
    "st.sidebar.title(\"Enter a hashtag\")\n",
    "hashtag = st.sidebar.text_input(\"hashtag\", \"trump\")\n",
    "date = st.sidebar.date_input(\"Analyse tweets from\", datetime.date(2020, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70950986",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.sidebar.button(\"Live analysis\", key=\"analyse\"):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    tweets_count = 0\n",
    "\n",
    "    st.subheader(f\"Analysing #{hashtag} from {date}\")\n",
    "    d = {\"Positive\": [pos_count], \"Negative\": [neg_count]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "\n",
    "    hashtag = f\"#{hashtag}\"\n",
    "    with st.spinner(\"Getting tweets...\"):\n",
    "        tweets = tw.Cursor(api.search_tweets, q=hashtag, lang=\"en\", since=date).items()\n",
    "\n",
    "    total_tweets = st.empty()\n",
    "    pos_tweets = st.empty()\n",
    "    neg_tweets = st.empty()\n",
    "\n",
    "    sentiments = [\"Positive\", \"Negative\"]\n",
    "    chart = st.line_chart(df)\n",
    "    barchart = st.empty()\n",
    "\n",
    "    for idx, tweet in enumerate(tweets):\n",
    "        tweets_count += 1\n",
    "        output = analyse_tweet(tweet.text)\n",
    "        #output = requests.post(\"analyse_tweet(tweet: Tweet)\", json={\"tweet\": tweet.text})\n",
    "        output = output.content.decode(\"utf8\")\n",
    "        output = json.loads(output).get(\"sentiment\")\n",
    "\n",
    "        if output == \"Negative\":\n",
    "            neg_count += 1\n",
    "        elif output == \"Positive\":\n",
    "            pos_count += 1\n",
    "\n",
    "        total_tweets.text(\"Tweets Analysed: %d\" % tweets_count)\n",
    "        pos_tweets.text(\"Positive tweets: %d\" % pos_count)\n",
    "        neg_tweets.text(\"Negative tweets: %d\" % neg_count)\n",
    "\n",
    "        df2 = pd.DataFrame({\"Positive\": [pos_count], \"Negative\": [neg_count]})\n",
    "        df.update(df2)\n",
    "        chart.add_rows(df)\n",
    "\n",
    "    if neg_count == 0 and pos_count == 0:\n",
    "        st.warning(f\"No Tweets Found on {hashtag}\")\n",
    "    else:\n",
    "        st.success(\"Tweets classified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9f2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
